{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training Analysis\n",
    "\n",
    "Visualize and interpret training runs for the StepMania difficulty classifier."
   ],
   "id": "b0947f03b6262565"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ],
   "id": "cfb2c04ed82c82c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Load Checkpoint",
   "id": "32ac93fb00d314a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CHECKPOINT_DIR = Path('../checkpoints')\n",
    "\n",
    "# List available checkpoints\n",
    "checkpoints = list(CHECKPOINT_DIR.glob('*.pt'))\n",
    "print(\"Available checkpoints:\")\n",
    "for cp in sorted(checkpoints):\n",
    "    print(f\"  {cp.name}\")"
   ],
   "id": "ef2a67846ee1b132"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load best checkpoint\n",
    "checkpoint_path = CHECKPOINT_DIR / 'best_val_loss.pt'\n",
    "if not checkpoint_path.exists():\n",
    "    checkpoint_path = CHECKPOINT_DIR / 'last.pt'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "print(f\"Loaded: {checkpoint_path.name}\")\n",
    "print(f\"Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "print(f\"Best val loss: {checkpoint.get('best_val_loss', 'N/A'):.4f}\")\n",
    "\n",
    "history = checkpoint.get('history', {})"
   ],
   "id": "a6ea69c6a621e198"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.5 Training Data Distribution\n",
    "\n",
    "Class balance from the actual data used during training (logged in checkpoint)."
   ],
   "id": "b1636e920715994e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display data distribution from checkpoint (if available)\n",
    "data_info = checkpoint.get('data_info', None)\n",
    "\n",
    "if data_info:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    for idx, (split_name, split_info) in enumerate(data_info.items()):\n",
    "        ax = axes[idx]\n",
    "        dist = split_info['difficulty_distribution']\n",
    "\n",
    "        # Convert to arrays for plotting\n",
    "        difficulties = list(range(1, 11))\n",
    "        counts = [dist.get(d, 0) for d in difficulties]\n",
    "\n",
    "        bars = ax.bar(difficulties, counts, color='steelblue', edgecolor='black')\n",
    "        ax.set_xlabel('Difficulty Level')\n",
    "        ax.set_ylabel('Number of Samples')\n",
    "        ax.set_title(f'{split_name.capitalize()} Set Distribution (n={split_info[\"total_samples\"]})')\n",
    "        ax.set_xticks(difficulties)\n",
    "\n",
    "        # Add count labels on bars\n",
    "        for bar, count in zip(bars, counts):\n",
    "            if count > 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                       str(count), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nData Distribution Summary:\")\n",
    "    for split_name, split_info in data_info.items():\n",
    "        dist = split_info['difficulty_distribution']\n",
    "        total = split_info['total_samples']\n",
    "        print(f\"\\n{split_name.upper()} ({total} samples):\")\n",
    "        for d in range(1, 11):\n",
    "            count = dist.get(d, 0)\n",
    "            pct = count / total * 100 if total > 0 else 0\n",
    "            bar = '#' * int(pct / 2)\n",
    "            print(f\"  Difficulty {d:2d}: {count:4d} ({pct:5.1f}%) {bar}\")\n",
    "else:\n",
    "    print(\"No data_info in checkpoint.\")\n",
    "    print(\"Re-run training to log data distribution (trainer now saves this automatically).\")"
   ],
   "id": "5bcef2637fc95d13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Loss Curves",
   "id": "a7324f683c3c55d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if history:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Loss\n",
    "    ax = axes[0]\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    ax.plot(epochs, history['train_loss'], 'b-', label='Train', linewidth=2)\n",
    "    ax.plot(epochs, history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training and Validation Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Find best epoch\n",
    "    best_epoch = np.argmin(history['val_loss']) + 1\n",
    "    best_val_loss = min(history['val_loss'])\n",
    "    ax.axvline(best_epoch, color='green', linestyle='--', alpha=0.7, label=f'Best (epoch {best_epoch})')\n",
    "    ax.scatter([best_epoch], [best_val_loss], color='green', s=100, zorder=5)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax = axes[1]\n",
    "    ax.plot(epochs, history['train_acc'], 'b-', label='Train', linewidth=2)\n",
    "    ax.plot(epochs, history['val_acc'], 'r-', label='Validation', linewidth=2)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('Training and Validation Accuracy')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    best_val_acc = max(history['val_acc'])\n",
    "    best_acc_epoch = np.argmax(history['val_acc']) + 1\n",
    "    ax.axvline(best_acc_epoch, color='green', linestyle='--', alpha=0.7)\n",
    "    ax.scatter([best_acc_epoch], [best_val_acc], color='green', s=100, zorder=5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Best validation loss: {best_val_loss:.4f} at epoch {best_epoch}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.4f} at epoch {best_acc_epoch}\")\n",
    "else:\n",
    "    print(\"No history found in checkpoint\")"
   ],
   "id": "fc68ae410504de44"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Overfitting Analysis",
   "id": "cf7be631c17586f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if history and len(history['train_loss']) > 5:\n",
    "    # Compute generalization gap\n",
    "    train_loss = np.array(history['train_loss'])\n",
    "    val_loss = np.array(history['val_loss'])\n",
    "    gap = val_loss - train_loss\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    epochs = range(1, len(gap) + 1)\n",
    "    ax.plot(epochs, gap, 'purple', linewidth=2)\n",
    "    ax.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax.fill_between(epochs, 0, gap, where=(gap > 0), color='red', alpha=0.3, label='Overfitting')\n",
    "    ax.fill_between(epochs, 0, gap, where=(gap <= 0), color='green', alpha=0.3, label='Underfitting')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Generalization Gap (Val - Train)')\n",
    "    ax.set_title('Overfitting Analysis')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    final_gap = gap[-1]\n",
    "    if final_gap > 0.5:\n",
    "        print(f\"WARNING: Significant overfitting detected (gap: {final_gap:.3f})\")\n",
    "        print(\"Consider: more dropout, data augmentation, or early stopping\")\n",
    "    elif final_gap < -0.1:\n",
    "        print(f\"Model may be underfitting (gap: {final_gap:.3f})\")\n",
    "        print(\"Consider: larger model, more epochs, or lower regularization\")\n",
    "    else:\n",
    "        print(f\"Good generalization (gap: {final_gap:.3f})\")"
   ],
   "id": "ee3ad990fc2f6d4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Learning Rate Analysis",
   "id": "d149694fbae4a50c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if history:\n",
    "    # Compute smoothed loss derivative to detect learning rate issues\n",
    "    train_loss = np.array(history['train_loss'])\n",
    "    \n",
    "    # Simple moving average\n",
    "    window = min(5, len(train_loss) // 3)\n",
    "    if window > 1:\n",
    "        smoothed = np.convolve(train_loss, np.ones(window)/window, mode='valid')\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        ax.plot(range(1, len(train_loss) + 1), train_loss, 'b-', alpha=0.3, label='Raw')\n",
    "        ax.plot(range(window, len(train_loss) + 1), smoothed, 'b-', linewidth=2, label='Smoothed')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Training Loss')\n",
    "        ax.set_title('Training Loss (Smoothed)')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Check for plateaus\n",
    "        recent_change = (smoothed[-1] - smoothed[-min(5, len(smoothed))]) / smoothed[-min(5, len(smoothed))]\n",
    "        if abs(recent_change) < 0.01:\n",
    "            print(\"Training has plateaued - LR reduction may have kicked in\")"
   ],
   "id": "b354c319f3e55bef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Confusion Matrix (if available)",
   "id": "3cf22909176df3b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Try to get confusion matrix from checkpoint\n",
    "confusion_matrix = checkpoint.get('confusion_matrix', None)\n",
    "\n",
    "# Also check inside metrics dict (where trainer actually saves it)\n",
    "if confusion_matrix is None and 'metrics' in checkpoint:\n",
    "    confusion_matrix = checkpoint['metrics'].get('confusion_matrix', None)\n",
    "\n",
    "if confusion_matrix is not None:\n",
    "    if isinstance(confusion_matrix, torch.Tensor):\n",
    "        confusion_matrix = confusion_matrix.cpu().numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Normalize by row (true labels)\n",
    "    cm_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=range(1, 11), yticklabels=range(1, 11), ax=ax)\n",
    "    ax.set_xlabel('Predicted Difficulty')\n",
    "    ax.set_ylabel('True Difficulty')\n",
    "    ax.set_title('Normalized Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    per_class_acc = np.diag(cm_normalized)\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, acc in enumerate(per_class_acc):\n",
    "        bar = '#' * int(acc * 20)\n",
    "        print(f\"  Difficulty {i+1:2d}: {acc:.2f} {bar}\")\n",
    "else:\n",
    "    print(\"No confusion matrix in checkpoint.\")\n",
    "    print(\"Run validation with confusion matrix tracking to generate one.\")"
   ],
   "id": "eed930398bc71571"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.1 Confusion Pattern Analysis\n",
    "\n",
    "Analyze where misclassifications go: off-by-1 errors vs distant jumps."
   ],
   "id": "7b5d5ec023f9e4af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if confusion_matrix is not None:\n",
    "    cm = confusion_matrix.astype('float')\n",
    "    num_classes = cm.shape[0]\n",
    "    total_samples = cm.sum()\n",
    "\n",
    "    # Categorize errors by distance\n",
    "    correct = np.trace(cm)\n",
    "    off_by_1 = 0\n",
    "    off_by_2 = 0\n",
    "    off_by_3_plus = 0\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            if i == j:\n",
    "                continue\n",
    "            distance = abs(i - j)\n",
    "            if distance == 1:\n",
    "                off_by_1 += cm[i, j]\n",
    "            elif distance == 2:\n",
    "                off_by_2 += cm[i, j]\n",
    "            else:\n",
    "                off_by_3_plus += cm[i, j]\n",
    "\n",
    "    total_errors = total_samples - correct\n",
    "\n",
    "    # Calculate MAE from confusion matrix\n",
    "    mae = 0\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            mae += cm[i, j] * abs(i - j)\n",
    "    mae /= total_samples\n",
    "\n",
    "    # Visualize error distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Pie chart of error types\n",
    "    ax = axes[0]\n",
    "    sizes = [correct, off_by_1, off_by_2, off_by_3_plus]\n",
    "    labels = ['Correct', 'Off-by-1', 'Off-by-2', 'Off-by-3+']\n",
    "    colors = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c']\n",
    "    explode = (0.05, 0, 0, 0)\n",
    "    ax.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',\n",
    "           shadow=True, startangle=90)\n",
    "    ax.set_title('Prediction Error Distribution')\n",
    "\n",
    "    # Error flow diagram (where do errors go?)\n",
    "    ax = axes[1]\n",
    "    error_flow = np.zeros((num_classes, 3))  # [under-predict, correct, over-predict]\n",
    "    for i in range(num_classes):\n",
    "        for j in range(num_classes):\n",
    "            if j < i:\n",
    "                error_flow[i, 0] += cm[i, j]  # Under-predicted\n",
    "            elif j == i:\n",
    "                error_flow[i, 1] += cm[i, j]  # Correct\n",
    "            else:\n",
    "                error_flow[i, 2] += cm[i, j]  # Over-predicted\n",
    "\n",
    "    # Normalize by row\n",
    "    row_sums = error_flow.sum(axis=1, keepdims=True)\n",
    "    error_flow_norm = np.divide(error_flow, row_sums, where=row_sums!=0)\n",
    "\n",
    "    x = np.arange(1, 11)\n",
    "    width = 0.25\n",
    "    ax.bar(x - width, error_flow_norm[:, 0], width, label='Under-predict', color='#3498db')\n",
    "    ax.bar(x, error_flow_norm[:, 1], width, label='Correct', color='#2ecc71')\n",
    "    ax.bar(x + width, error_flow_norm[:, 2], width, label='Over-predict', color='#e74c3c')\n",
    "    ax.set_xlabel('True Difficulty')\n",
    "    ax.set_ylabel('Proportion')\n",
    "    ax.set_title('Prediction Direction by True Class')\n",
    "    ax.set_xticks(x)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print summary\n",
    "    print(\"Error Analysis Summary:\")\n",
    "    print(f\"  Total samples:  {int(total_samples)}\")\n",
    "    print(f\"  Correct:        {int(correct)} ({100*correct/total_samples:.1f}%)\")\n",
    "    print(f\"  Off-by-1:       {int(off_by_1)} ({100*off_by_1/total_samples:.1f}%)\")\n",
    "    print(f\"  Off-by-2:       {int(off_by_2)} ({100*off_by_2/total_samples:.1f}%)\")\n",
    "    print(f\"  Off-by-3+:      {int(off_by_3_plus)} ({100*off_by_3_plus/total_samples:.1f}%)\")\n",
    "    print(f\"\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {mae:.3f}\")\n",
    "    print(f\"  (Lower is better - perfect model has MAE=0)\")\n",
    "\n",
    "    # Interpretation\n",
    "    if off_by_1 / max(total_errors, 1) > 0.5:\n",
    "        print(f\"\\n  Most errors are adjacent - ordinal regression may help!\")\n",
    "    elif off_by_3_plus / max(total_errors, 1) > 0.3:\n",
    "        print(f\"\\n  Many distant errors - model has fundamental discrimination issues\")\n",
    "else:\n",
    "    print(\"No confusion matrix available for error analysis.\")"
   ],
   "id": "ec32c2e2043f4ae8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.2 Per-Class Precision, Recall, and F1\n",
    "\n",
    "Detailed classification metrics for each difficulty level."
   ],
   "id": "fb8bcc22870f9e97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if confusion_matrix is not None:\n",
    "    cm = confusion_matrix.astype('float')\n",
    "    num_classes = cm.shape[0]\n",
    "\n",
    "    # Calculate precision, recall, F1 for each class\n",
    "    precision = np.zeros(num_classes)\n",
    "    recall = np.zeros(num_classes)\n",
    "    f1 = np.zeros(num_classes)\n",
    "    support = np.zeros(num_classes)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i, i]\n",
    "        fp = cm[:, i].sum() - tp  # Column sum minus diagonal\n",
    "        fn = cm[i, :].sum() - tp  # Row sum minus diagonal\n",
    "\n",
    "        precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "        support[i] = cm[i, :].sum()\n",
    "\n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Bar chart of metrics\n",
    "    ax = axes[0]\n",
    "    x = np.arange(1, 11)\n",
    "    width = 0.25\n",
    "    ax.bar(x - width, precision, width, label='Precision', color='#3498db')\n",
    "    ax.bar(x, recall, width, label='Recall', color='#e74c3c')\n",
    "    ax.bar(x + width, f1, width, label='F1', color='#2ecc71')\n",
    "    ax.set_xlabel('Difficulty Level')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Precision, Recall, F1 by Class')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend()\n",
    "    ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # Heatmap of metrics\n",
    "    ax = axes[1]\n",
    "    metrics_matrix = np.vstack([precision, recall, f1])\n",
    "    sns.heatmap(metrics_matrix, annot=True, fmt='.2f', cmap='RdYlGn',\n",
    "                xticklabels=range(1, 11), yticklabels=['Precision', 'Recall', 'F1'],\n",
    "                ax=ax, vmin=0, vmax=1, center=0.5)\n",
    "    ax.set_xlabel('Difficulty Level')\n",
    "    ax.set_title('Classification Metrics Heatmap')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print detailed table\n",
    "    print(\"Per-Class Classification Metrics:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Difficulty':>10} {'Precision':>10} {'Recall':>10} {'F1':>10} {'Support':>10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for i in range(num_classes):\n",
    "        print(f\"{i+1:>10} {precision[i]:>10.3f} {recall[i]:>10.3f} {f1[i]:>10.3f} {int(support[i]):>10}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Macro and weighted averages\n",
    "    macro_precision = precision.mean()\n",
    "    macro_recall = recall.mean()\n",
    "    macro_f1 = f1.mean()\n",
    "\n",
    "    weighted_precision = (precision * support).sum() / support.sum()\n",
    "    weighted_recall = (recall * support).sum() / support.sum()\n",
    "    weighted_f1 = (f1 * support).sum() / support.sum()\n",
    "\n",
    "    print(f\"{'Macro Avg':>10} {macro_precision:>10.3f} {macro_recall:>10.3f} {macro_f1:>10.3f} {int(support.sum()):>10}\")\n",
    "    print(f\"{'Weighted':>10} {weighted_precision:>10.3f} {weighted_recall:>10.3f} {weighted_f1:>10.3f} {int(support.sum()):>10}\")\n",
    "\n",
    "    # Identify problem classes\n",
    "    problem_classes = np.where(f1 < 0.3)[0]\n",
    "    if len(problem_classes) > 0:\n",
    "        print(f\"\\nProblem classes (F1 < 0.3): {[c+1 for c in problem_classes]}\")\n",
    "        for c in problem_classes:\n",
    "            if recall[c] < precision[c]:\n",
    "                print(f\"  Difficulty {c+1}: Low recall - model misses many samples of this class\")\n",
    "            else:\n",
    "                print(f\"  Difficulty {c+1}: Low precision - model over-predicts this class\")\n",
    "else:\n",
    "    print(\"No confusion matrix available for metrics calculation.\")"
   ],
   "id": "d9c6e6e51ec86b34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Training Summary",
   "id": "7ed662264558f50c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if history:\n",
    "    n_epochs = len(history['train_loss'])\n",
    "    final_train_loss = history['train_loss'][-1]\n",
    "    final_val_loss = history['val_loss'][-1]\n",
    "    final_train_acc = history['train_acc'][-1]\n",
    "    final_val_acc = history['val_acc'][-1]\n",
    "    best_val_loss = min(history['val_loss'])\n",
    "    best_val_acc = max(history['val_acc'])\n",
    "    \n",
    "    print(f\"Epochs completed: {n_epochs}\")\n",
    "    print(f\"\")\n",
    "    print(f\"Final metrics:\")\n",
    "    print(f\"  Train loss: {final_train_loss:.4f}\")\n",
    "    print(f\"  Val loss:   {final_val_loss:.4f}\")\n",
    "    print(f\"  Train acc:  {final_train_acc:.4f}\")\n",
    "    print(f\"  Val acc:    {final_val_acc:.4f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"Best metrics:\")\n",
    "    print(f\"  Val loss:   {best_val_loss:.4f}\")\n",
    "    print(f\"  Val acc:    {best_val_acc:.4f}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"Recommendations:\")\n",
    "    if final_val_acc < 0.3:\n",
    "        print(\"  - Model struggling. Check data quality and class balance.\")\n",
    "    elif final_val_acc < 0.5:\n",
    "        print(\"  - Moderate performance. Consider longer training or architecture changes.\")\n",
    "    elif final_val_acc < 0.7:\n",
    "        print(\"  - Good progress. Fine-tune hyperparameters for better results.\")\n",
    "    else:\n",
    "        print(\"  - Strong performance! Consider ensemble or test set evaluation.\")\n",
    "    \n",
    "    if final_val_loss > final_train_loss * 1.5:\n",
    "        print(\"  - Overfitting detected. Add regularization or data augmentation.\")\n",
    "else:\n",
    "    print(\"No training history available.\")"
   ],
   "id": "23466c1f3c1d2f7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Model Architecture Info",
   "id": "e15d7beeb5934e92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if 'model_state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in state_dict.values())\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"\")\n",
    "    print(\"Layer sizes:\")\n",
    "    for name, param in state_dict.items():\n",
    "        if 'weight' in name:\n",
    "            print(f\"  {name}: {list(param.shape)}\")"
   ],
   "id": "aa9511c454e0fbac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Chart Statistics Correlation (if available)\n",
    "\n",
    "Analyze how the engineered chart statistics features correlate with difficulty levels."
   ],
   "id": "e4448d6817e00ff9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Chart statistics analysis\n",
    "# Note: This section will show data after retraining with chart_stats enabled\n",
    "# The chart_stats features (notes/sec, jump_ratio, etc.) are computed per-sample\n",
    "\n",
    "# Check if chart_stats summary was saved in checkpoint\n",
    "chart_stats_summary = checkpoint.get('chart_stats_summary', None)\n",
    "\n",
    "if chart_stats_summary is not None:\n",
    "    stat_names = ['Notes/sec', 'Jump ratio', 'Max stream', 'Avg gap', 'Peak density']\n",
    "\n",
    "    # Display stats by difficulty\n",
    "    print(\"Chart Statistics by Difficulty Level:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Difficulty':>10} \" + \" \".join(f\"{name:>12}\" for name in stat_names))\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    for d in range(1, 11):\n",
    "        if d in chart_stats_summary:\n",
    "            stats = chart_stats_summary[d]\n",
    "            print(f\"{d:>10} \" + \" \".join(f\"{s:>12.2f}\" for s in stats['mean']))\n",
    "\n",
    "    print(\"\\nNote: These are mean values per difficulty level\")\n",
    "else:\n",
    "    print(\"No chart_stats_summary in checkpoint.\")\n",
    "    print(\"\")\n",
    "    print(\"To enable this analysis:\")\n",
    "    print(\"  1. The model now computes chart statistics (notes/sec, jump_ratio, etc.)\")\n",
    "    print(\"  2. After retraining, these features will be used for classification\")\n",
    "    print(\"  3. To see correlations, we need to add chart_stats_summary logging to the trainer\")\n",
    "    print(\"\")\n",
    "    print(\"Current chart_stats features (computed in dataset.py):\")\n",
    "    print(\"  - notes_per_second: Total notes / song duration\")\n",
    "    print(\"  - jump_ratio: Fraction of timesteps with 2+ simultaneous notes\")\n",
    "    print(\"  - max_stream_length: Longest consecutive run of non-empty timesteps\")\n",
    "    print(\"  - avg_gap: Average gap between notes (in timesteps)\")\n",
    "    print(\"  - peak_density: Max notes in any 16-beat window\")"
   ],
   "id": "bafa5e167dcc9a5a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "154dc303c294a099"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fa584ed50fffb74a"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
