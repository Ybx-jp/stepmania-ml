# Model architecture configuration

# Difficulty classification model
# Target: 5 difficulty name classes (Beginner, Easy, Medium, Hard, Challenge)
classifier:
  # Input dimensions
  audio_features_dim: 13  # MFCC features
  chart_sequence_dim: 4   # 4-panel arrows
  max_sequence_length: 1440  # 2 minutes at 16th note resolution (120s / 0.125s)

  # Audio encoder
  audio_encoder:
    hidden_dim: 128
    num_layers: 2
    dropout: 0.3

  # Chart encoder
  chart_encoder:
    embedding_dim: 64
    hidden_dim: 128
    num_layers: 2
    dropout: 0.3

  # Fusion and classification
  fusion_dim: 256
  num_classes: 5  # Difficulty names: Beginner, Easy, Medium, Hard, Challenge
  classifier_dropout: 0.2

  # Backbone temporal reasoning
  backbone_blocks: 4
  backbone_dropout: 0.4

  # Architecture options
  fusion_type: "late"  # late
  pooling_type: "mean_max"  # attention, mean_max
  head_type: "classification"  # classification (reverted from ordinal)
  classifier_hidden_dim: 64 # Add hidden layer before classification

  # Chart statistics features for difficulty prediction
  use_chart_stats: true
  chart_stats_dim: 5        # Number of statistics features
  stats_hidden_dim: 8      # MLP hidden dimension
  stats_dropout: 0.5

# Diffusion generative model
diffusion:
  # Model architecture
  model_type: "unet1d"  # 1D U-Net for sequence generation

  # Input/output dimensions
  chart_dim: 4  # 4-panel arrows
  audio_condition_dim: 256
  difficulty_condition_dim: 16  # Embedded difficulty
  max_sequence_length: 960

  # U-Net settings
  unet:
    base_channels: 64
    channel_multipliers: [1, 2, 4, 8]
    num_res_blocks: 2
    attention_resolutions: [16, 8]
    dropout: 0.1

  # Diffusion process
  diffusion_steps: 1000
  noise_schedule: "cosine"  # cosine, linear

  # Conditioning
  use_audio_conditioning: true
  use_difficulty_conditioning: true
  condition_dropout: 0.1  # For classifier-free guidance

# Training hyperparameters (default values)
training:
  # Device configuration
  device: "cpu"  # "cpu" or "cuda"
  pin_memory: false  # Set true only when using CUDA

  batch_size: 32
  learning_rate: 0.0001
  num_classes: 5  # Difficulty names: Beginner, Easy, Medium, Hard, Challenge
  num_epochs: 15
  early_stopping_patience: 5
  gradient_clip_norm: 1.0

  # Class weighting for imbalanced data
  use_class_weights: true  # Compute inverse-frequency weights from training data

  # Optimizer
  optimizer: "adamw"
  weight_decay: 0.01

  # Scheduler - ReduceLROnPlateau
  scheduler: "reduce_on_plateau"
  patience: 3
  factor: 0.5
  monitor: "val_loss"