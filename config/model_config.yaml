# Model architecture configuration

# Difficulty classification model
# Target: 5 difficulty name classes (Beginner, Easy, Medium, Hard, Challenge)
classifier:
  # Input dimensions
  # Audio features: MFCC (13) + onset_env (1) + onset_rate (1) + tempo (1) + spectral_contrast (7) = 23
  audio_features_dim: 23
  chart_sequence_dim: 4   # 4-panel arrows
  max_sequence_length: 1440  # 2 minutes at 16th note resolution (120s / 0.125s)

  # Audio encoder
  audio_encoder:
    hidden_dim: 128
    num_layers: 2
    dropout: 0.3

  # Chart encoder
  chart_encoder:
    embedding_dim: 64
    hidden_dim: 128
    num_layers: 2
    dropout: 0.3

  # Fusion and classification
  fusion_dim: 256
  num_classes: 4  # Difficulty names: Beginner, Easy, Medium, Hard (Challenge folded into Hard)
  classifier_dropout: 0.2

  # Backbone temporal reasoning
  backbone_blocks: 4
  backbone_dropout: 0.4

  # Architecture options
  fusion_type: "late"  # late
  pooling_type: "mean_max"  # attention, mean_max
  head_type: "classification"  # classification (reverted from ordinal)
  classifier_hidden_dim: 64 # Add hidden layer before classification

  # Groove radar features for difficulty prediction and contrastive learning
  # Replaces chart_stats with DDR-style groove radar values
  use_groove_radar: true
  radar_hidden_dim: 32      # MLP hidden dimension for groove radar branch
  radar_dropout: 0.3

  # Projection head for contrastive learning (optional)
  use_projection_head: false  # Enable for contrastive training
  projection_dim: 128         # Embedding dimension for contrastive loss

# Diffusion generative model
diffusion:
  # Model architecture
  model_type: "unet1d"  # 1D U-Net for sequence generation

  # Input/output dimensions
  chart_dim: 4  # 4-panel arrows
  audio_condition_dim: 256
  difficulty_condition_dim: 16  # Embedded difficulty
  max_sequence_length: 960

  # U-Net settings
  unet:
    base_channels: 64
    channel_multipliers: [1, 2, 4, 8]
    num_res_blocks: 2
    attention_resolutions: [16, 8]
    dropout: 0.1

  # Diffusion process
  diffusion_steps: 1000
  noise_schedule: "cosine"  # cosine, linear

  # Conditioning
  use_audio_conditioning: true
  use_difficulty_conditioning: true
  condition_dropout: 0.1  # For classifier-free guidance

# Training hyperparameters (default values)
training:
  batch_size: 64
  learning_rate: 0.0001
  num_classes: 4  # Difficulty names: Beginner, Easy, Medium, Hard (Challenge folded into Hard)
  num_epochs: 15
  early_stopping_patience: 5
  gradient_clip_norm: 1.0

  # Class weighting for imbalanced data
  use_class_weights: true  # Compute inverse-frequency weights from training data

  # Optimizer
  optimizer: "adamw"
  weight_decay: 0.01

  # Scheduler - ReduceLROnPlateau
  scheduler: "reduce_on_plateau"
  patience: 3
  factor: 0.5
  monitor: "val_loss"

# Contrastive learning settings
contrastive:
  enabled: true  # Set to true to enable contrastive training

  # Loss type: 'triplet_radar' (with adaptive margins) or 'triplet' or 'infonce'
  contrastive_loss: 'triplet_radar'

  # Triplet loss settings
  triplet_margin: 1.0       # Base margin for triplet loss
  margin_scale: 0.5         # Scale factor for groove radar-based adaptive margins

  # InfoNCE settings (if using infonce loss)
  infonce_temperature: 0.07

  # Multi-task loss weights
  classification_weight: 0.8  # Weight for classification loss
  contrastive_weight: 1.0     # Weight for contrastive loss

  # Triplet selection settings
  positive_percentile: 20.0   # Top 20% most similar are "positive"
  negative_percentile: 80.0   # Top 20% most dissimilar are "negative"
  same_difficulty_only: false # If true, only match within same difficulty class

  # Groove radar weights for similarity (optional)
  # [stream, voltage, air, freeze, chaos] - equal by default
  radar_weights: [1.0, 1.0, 1.0, 1.0, 1.0]

  # Dataset settings
  precompute_triplets: true   # Precompute triplet indices at startup
  resample_epoch: true        # Resample triplets each epoch for variety